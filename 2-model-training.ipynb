{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install LangChain\n",
    "# %pip install langchain\n",
    "# %pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Step 2: Load and preprocess the data\n",
    "house_loan_dir = './data/house-loan'\n",
    "house_loan_data = {}\n",
    "\n",
    "for filename in os.listdir(house_loan_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(house_loan_dir, filename), 'r', encoding='utf-8') as file:\n",
    "            house_loan_data[filename] = file.read()\n",
    "\n",
    "# Combine all data into a single string\n",
    "combined_data = \"\\n\\n\".join(house_loan_data.values())\n",
    "\n",
    "# Step 3: Create a LangChain model\n",
    "llm = Ollama(model=\"llama3.1\")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = f\"\"\"\n",
    "You are a financial advisor chatbot. Use the following data to answer questions about house loans and other financial topics:\n",
    "\n",
    "{combined_data}\n",
    "\n",
    "You can answer questions about:\n",
    "1. Features of house loans\n",
    "2. Requirements for house loans\n",
    "3. Bank URLs\n",
    "4. General financial advice\n",
    "5. Investment options\n",
    "6. Savings plans\n",
    "\n",
    "hen answering, cross-reference information from all available data to provide the most accurate and comprehensive response. If the user asks for follow-up information, continue to use the data to provide detailed answers.\n",
    "\n",
    "You must limit your responses to financial topics only.\n",
    "\n",
    "User: {{input}} \n",
    "\"\"\"\n",
    "\n",
    "# Step 4: Invoke the model\n",
    "\n",
    "\n",
    "def get_response(user_input):\n",
    "    prompt = prompt_template.format(input=user_input)\n",
    "    response = llm.invoke(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "user_query = \"What are the requirements for the house loan from Canadia Bank?\"\n",
    "response = get_response(user_query)\n",
    "print(\"Chatbot Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create a simple chat interface\n",
    "def chat():\n",
    "    print(\"Welcome to the Financial Advisor Chatbot. Type 'exit' to end the chat.\")\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        response = get_response(user_input)\n",
    "        print(f\"Chatbot: {response}\")\n",
    "\n",
    "\n",
    "# Run the chat interface\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
